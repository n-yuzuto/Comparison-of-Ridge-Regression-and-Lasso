# Comparison-of-Ridge-Regression-and-Lasso
Wineデータを訓練事例とテスト事例に分割し、訓練事例でridge回帰とLASSOを学習させました。  
正則化パラメータ(alpha)は2^-16,2^-15,...,2^12まで変化させ次の3つを出力しました。
 - 正則化パラメータ
 - 各特徴量とそれに対応する係数(昇順にソート)
 - 訓練誤差およびテスト誤差.  
 
 ## 考察
 テスト誤差が最小になる正則化パラメータにおいては、ラッソのテスト誤差がリッジ回帰よりわずかに小さいが、これはデータセットの選び方で変動するほどの非常に小さな差であり、ラッソとリッジ回帰の差はほとんどないと言える。  
 
 テスト誤差が最小になる正則化パラメータにおけるラッソでは、対応するモデルパラメータがゼロとなる特徴は存在せず、この設定では特徴選択の効果は見られていない。



***
.ipynbファイルが開かれない時は、こちらのリンクにURLを貼ってご覧になってください。  
[nbviewer](https://nbviewer.jupyter.org/)
